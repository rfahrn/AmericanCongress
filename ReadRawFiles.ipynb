{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32b7a04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import pickle\n",
    "from io import StringIO\n",
    "import re\n",
    "\n",
    "DATA_BASE_PATH = \"./hein-daily/\"\n",
    "DATA_SAVE_PATH = \"./preprocessed_data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed0edda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_disk(data, full_path):\n",
    "    with open(full_path, 'wb') as file:\n",
    "        pickle.dump(data, file, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def read_from_disk(full_path):\n",
    "    with open(full_path, 'rb') as file:\n",
    "        data = pickle.load(file)\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b22a0631",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_raw_files(base_path, filename_description = \"\", filename_rule = \"\", splitby_rule = \"\", take_splitelem = 0, delimiter = \"|\", encoding = None, replace_first_n_delims = 0):\n",
    "    \n",
    "    all_files = None\n",
    "    \n",
    "    for path in glob.glob(base_path + filename_rule):\n",
    "        print(path)\n",
    "        \n",
    "        file_number = path.split(\"/\")[-1].split(splitby_rule)[take_splitelem].split(\".txt\")[0]\n",
    "        \n",
    "        # in case of structurally corrupted file \n",
    "        if replace_first_n_delims > 0:\n",
    "            custom_delim = \"째@@째\"\n",
    "            dummy_file = replace_delimiters(path, encoding = encoding, replace_first_n = replace_first_n_delims, find_delim = delimiter, replace_with = custom_delim) \n",
    "            df = pd.read_csv(dummy_file, delimiter = custom_delim, encoding = encoding)\n",
    "    \n",
    "        # healthy file \n",
    "        else:\n",
    "            df = pd.read_csv(path, delimiter = delimiter, encoding = encoding)\n",
    "       \n",
    "    \n",
    "        # add file info \n",
    "        df[filename_description] = file_number\n",
    "        \n",
    "        if all_files is None:\n",
    "            all_files = df.copy(deep = True)\n",
    "        else:\n",
    "            all_files = pd.concat([all_files,df])\n",
    "            \n",
    "        \n",
    "    return all_files.reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def replace_delimiters(file_path, encoding = None, replace_first_n = 1, find_delim = \"|\", replace_with = \"째@@째\"):\n",
    "    '''\n",
    "    In some files, the delimiter occurs again within the content, corrupting the file structure.\n",
    "    Thus, replace the first n correctly placed delimiters with another delimiter. \n",
    "    Credit: https://stackoverflow.com/a/48672386 \n",
    "    '''\n",
    "    \n",
    "    file_dummy = StringIO()\n",
    "    with open(file_path, encoding = encoding) as file:\n",
    "        for line in file:\n",
    "           \n",
    "            new_line = line.replace(find_delim, replace_with,1)\n",
    "            print(new_line, file=file_dummy)\n",
    "    \n",
    "    file_dummy.seek(0)\n",
    "    \n",
    "    return file_dummy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f054a2e",
   "metadata": {},
   "source": [
    "# Read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "623f247c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#speakermaps = read_raw_files(base_path = DATA_BASE_PATH, filename_description = \"speakermap_filename\", filename_rule = \"*SpeakerMap.*\", splitby_rule = \"_SpeakerMap\", take_splitelem = 0, delimiter = \"|\")   \n",
    "#byparty_2grams = read_raw_files(base_path = DATA_BASE_PATH, filename_description = \"byparty_2gram_filename\", filename_rule = \"*byparty_2gram_*\", splitby_rule = \"byparty_2gram_\", take_splitelem = 1, delimiter = \"|\")\n",
    "#byspeaker_2grams = read_raw_files(base_path = DATA_BASE_PATH, filename_description = \"byspeaker_2gram_filename\", filename_rule = \"*byspeaker_2gram_*\", splitby_rule = \"byspeaker_2gram_\", take_splitelem = 1, delimiter = \"|\")\n",
    "#descriptions = read_raw_files(base_path = DATA_BASE_PATH, filename_description = \"descriptions_filename\", filename_rule = \"*descr_*\", splitby_rule = \"descr_\", take_splitelem = 1, delimiter = \"|\")   \n",
    "#speeches = read_raw_files(base_path = DATA_BASE_PATH, filename_description = \"speeches_filename\", filename_rule = \"*speeches_*\", splitby_rule = \"speeches_\", take_splitelem = 1, delimiter = \"|\", encoding = \"iso-8859-1\", replace_first_n_delims = 1)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376fd8a6",
   "metadata": {},
   "source": [
    "# Write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "077b3476",
   "metadata": {},
   "outputs": [],
   "source": [
    "#write_to_disk(speakermaps, DATA_SAVE_PATH + \"raw_speakermaps.pickle\")\n",
    "#write_to_disk(byparty_2grams, DATA_SAVE_PATH + \"raw_byparty_2grams.pickle\")\n",
    "#write_to_disk(byspeaker_2grams, DATA_SAVE_PATH + \"raw_byspeaker_2grams.pickle\")\n",
    "#write_to_disk(descriptions, DATA_SAVE_PATH + \"raw_descriptions.pickle\")\n",
    "#write_to_disk(speeches, DATA_SAVE_PATH + \"raw_speeches.pickle\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
